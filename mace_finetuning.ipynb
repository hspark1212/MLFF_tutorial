{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hspark1212/MLFF_tutorial/blob/main/mace_finetuning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ðŸ“˜ MACE Tutorial for Group Research Day 2024\n",
        "\n",
        "Welcome to the MACE Tutorial for Group Research Day 2024! ðŸŒŸ This tutorial will guide you through the process of fine-tuning MACE on custom datset.\n",
        "The foundation model, `MACE-MP` will be working with us, was initially trained on the Materials Project Trajectory (MPTraj) dataset.\n",
        "\n",
        "This tutorial is divided into the following sections:\n",
        "\n",
        "**1. Installation**: Set up your environment with the necessary tools and packages.\n",
        "\n",
        "**2. Exploring MACE**: Learn about how to get energy and force predictions from MACE-MP.\n",
        "\n",
        "**3. Making a Dataset**: Prepare your dataset for finetuning MACE-MP\n",
        "\n",
        "**4. Training**: Fine-tune MACE-MP on your custom dataset.\n",
        "\n",
        "**5. Evaluation**: Evaluate the performance of your fine-tuned MACE model.\n",
        "\n",
        "**6. Application** - Molecular Dynamics (MD) Simulation: Put your new MACE model into action with a simple MD simulation of copper.\n",
        "\n",
        "So let's dive in and get started! ðŸš€"
      ],
      "metadata": {
        "id": "yC71QD_Sl7cW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 0. Installation\n",
        "\n",
        "First, letâ€™s get your environment ready by installing the necessary packages.\n",
        "\n",
        "> Our tutorial uses `mace-torch==0.3.6` and MACE is continuously being updated. Please check the latest version of MACE on the [MACE GitHub page](https://github.com/ACEsuit/mace)"
      ],
      "metadata": {
        "id": "9jFGVGbumBMY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install -q mace-torch==0.3.6\n",
        "! pip install -q seaborn"
      ],
      "metadata": {
        "id": "h6hMDLfymH_m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Weâ€™ll also import some libraries for this tutorial."
      ],
      "metadata": {
        "id": "ZfQO6UABmKfd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import defaultdict\n",
        "from pprint import pprint\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from IPython.display import HTML, display\n",
        "from matplotlib.animation import FuncAnimation\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from ase import Atoms\n",
        "from ase import units\n",
        "from ase.io import read, write\n",
        "from ase.build import bulk\n",
        "from ase.visualize import view\n",
        "from ase.visualize.plot import plot_atoms\n",
        "from ase.md.velocitydistribution import MaxwellBoltzmannDistribution\n",
        "from ase.md.langevin import Langevin\n",
        "\n",
        "from mace.calculators import mace_mp\n",
        "\n",
        "plt.rcParams[\"font.size\"] = 15\n",
        "sns.set_style(\"whitegrid\")"
      ],
      "metadata": {
        "id": "175-Hygwm1W_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Exploring MACE\n",
        "\n",
        "Now that we have MACE installed, let's get a better understanding of what it can do. In this section, we'll explore an example of MACE in action, where we model the interaction between copper atoms at varying distances."
      ],
      "metadata": {
        "id": "MmOyZ1FqnmSt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creating Copper Diatomic Molecules at Various Distances\n",
        "\n",
        "We will create a series of copper diatomic molecules (Cu2) with different interatomic distances ranging from 0.6 Ã… to 5.0 Ã…."
      ],
      "metadata": {
        "id": "JA-lOI0I0LoD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "distances = np.arange(0.6, 5.1, 0.1)\n",
        "atoms_list = []\n",
        "for dist in distances:\n",
        "    atoms = Atoms(\n",
        "        \"Cu2\", positions=[[0, 0, 0], [0, 0, dist]], cell=[20, 20, 20], pbc=True\n",
        "    )\n",
        "    atoms.info[\"dist\"] = dist\n",
        "    atoms_list.append(atoms)"
      ],
      "metadata": {
        "id": "7bThF6uKm-Es"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Visualizing the Copper Diatomic Molecules\n",
        "\n",
        "To visualize these copper atoms, we use matplotlib to create an animation that shows how the atomic configuration changes as the distance between the atoms varies.\n"
      ],
      "metadata": {
        "id": "he_3iHmD0btk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots()\n",
        "\n",
        "def update(frame):\n",
        "    ax.clear()\n",
        "    ax.set_axis_off()\n",
        "    atoms = atoms_list[frame]\n",
        "    plot_atoms(atoms, ax=ax, show_unit_cell=2, rotation=(\"90x,0y,0z\"))\n",
        "    plt.title(f\"{atoms.info['dist']:.2f} Ã…\")\n",
        "    return ax\n",
        "\n",
        "\n",
        "ani = FuncAnimation(fig, func=update, frames=len(atoms_list), repeat=False)\n",
        "display(HTML(ani.to_jshtml()))\n",
        "plt.close(fig)"
      ],
      "metadata": {
        "id": "a9BcSiyWsTnm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loading MACE models with ASE Calculator\n",
        "\n",
        "We are going to use two different MACE models to calculate the potential energy and forces for each configuration of copper atoms:\n",
        "\n",
        "*   `MACE-MP`: This model was trained on the MPTraj dataset but may struggle to accurately predict energies when atoms are very close together due to high repulsive forces.\n",
        "\n",
        "*   `MACE-MP-0b`: This model incorporates a ZBL (Ziegler-Biersack-Littmark) potential with `MACE-MP`, which is better suited for handling high-repulsion situations when atoms are extremely close together."
      ],
      "metadata": {
        "id": "BFQUp5VF2_Gs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mace_mp_calc = mace_mp(\n",
        "    model=\"medium\",\n",
        "    device=\"cpu\",\n",
        ")\n",
        "\n",
        "mace_mp_0b_calc = mace_mp(\n",
        "    model=\"https://github.com/ACEsuit/mace-mp/releases/download/mace_mp_0b/mace_agnesi_medium.model\",\n",
        "    device=\"cpu\",\n",
        ")"
      ],
      "metadata": {
        "id": "G_WTzB0BuLVR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check it out other parameters\n",
        "help(mace_mp)"
      ],
      "metadata": {
        "id": "AB8u1AuAVFKU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Calculating and Collecting Energies and Forces\n",
        "\n",
        "We calculate the energies and forces for each configuration using both models and collect the data."
      ],
      "metadata": {
        "id": "bh5xiUPe3Gn2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "collections = defaultdict(list)\n",
        "for i, atoms in enumerate(atoms_list):\n",
        "    # Calculate the energy and forces from MACE-MP\n",
        "    e_mace_mp = mace_mp_calc.get_potential_energy(atoms)\n",
        "    f_mace_mp = mace_mp_calc.get_forces(atoms)\n",
        "\n",
        "    # Calculate the energy and forces from MACE-MP-0b\n",
        "    e_mace_mp_0b = mace_mp_0b_calc.get_potential_energy(atoms)\n",
        "    f_mace_mp_0b = mace_mp_0b_calc.get_forces(atoms)\n",
        "\n",
        "    # Collect the data\n",
        "    dist = distances[i]\n",
        "    collections[\"dist\"].append(dist)\n",
        "    collections[\"atoms\"].append(atoms)\n",
        "    collections[\"e_mace_mp\"].append(e_mace_mp)\n",
        "    collections[\"f_mace_mp\"].append(f_mace_mp)\n",
        "    collections[\"e_mace_mp_0b\"].append(e_mace_mp_0b)\n",
        "    collections[\"f_mace_mp_0b\"].append(f_mace_mp_0b)\n",
        "df = pd.DataFrame(collections)"
      ],
      "metadata": {
        "id": "OvjcCN3lwpLE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "lxBXZ9LiUHDr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Plotting diatomic energy\n",
        "\n",
        "We plot the potential energy as a function of the interatomic distance for both models."
      ],
      "metadata": {
        "id": "6_rwibdM3N5Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots(1, 1, figsize=(6, 4))\n",
        "sns.lineplot(data=df, x=\"dist\", y=\"e_mace_mp\", label=\"MACE-MP\", marker=\"o\", ax=ax)\n",
        "sns.lineplot(data=df, x=\"dist\", y=\"e_mace_mp_0b\", label=\"MACE-MP-0b\", marker=\"o\", ax=ax)\n",
        "ax.set_title(\"Cu\")\n",
        "ax.set_xlabel(\"Distance [Ã…]\")\n",
        "ax.set_ylabel(\"Energy [eV]\")\n",
        "ax.set_ylim(-10, 50)\n",
        "ax.axhline(0, color=\"black\", linestyle=\"--\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "UovQh_fXxyIr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Making a Dataset\n",
        "\n",
        "In this section, we'll prepare your dataset for fine-tuning the MACE-MP model."
      ],
      "metadata": {
        "id": "xt48-xeqyHEc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preparing the Dataset with Reference Energies and Forces\n",
        "We will use the energies and forces from the `MACE-MP-0b` model as our reference data for fine-tuning.\n",
        "\n",
        "When preparing the dataset for training MACE, it is essential to store the energy on `atoms.info` and the forces on `atoms.arrays`.\n",
        "\n",
        ">Note: From ASE version 3.23.0, storing energy information under `atoms.info[\"energy\"]` will be omitted during the reading process using `ase.io.read`. Therefore, it is necessary to use an alternative label. The MACE recommends using `atoms.info[\"REF_energy\"]` to avoid these issues."
      ],
      "metadata": {
        "id": "gcDuU4Fd3zkp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = []\n",
        "for i, row in df.iterrows():\n",
        "    atoms = row[\"atoms\"].copy()\n",
        "    atoms.info[\"dist\"] = row[\"dist\"]\n",
        "    atoms.info[\"REF_energy\"] = row[\"e_mace_mp_0b\"]\n",
        "    atoms.arrays[\"REF_forces\"] = row[\"f_mace_mp_0b\"]\n",
        "    dataset.append(atoms)"
      ],
      "metadata": {
        "id": "MZVSMLNLyNxU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Saving the Dataset\n",
        "We save the dataset into training, validation, and test files."
      ],
      "metadata": {
        "id": "W7yZ4OPb4Thi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "write(\"train.xyz\", dataset)\n",
        "write(\"valid.xyz\", dataset)\n",
        "write(\"test.xyz\", dataset)"
      ],
      "metadata": {
        "id": "CbTeEao5yOsZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loading and Inspecting the Dataset\n",
        "We read the dataset back into memory and inspect it."
      ],
      "metadata": {
        "id": "4KmIs-ma4WLK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train = read(\"train.xyz\", index=\":\")\n",
        "valid = read(\"valid.xyz\", index=\":\")\n",
        "test = read(\"test.xyz\", index=\":\")\n",
        "len(train), len(valid), len(test)"
      ],
      "metadata": {
        "id": "ozYG0skyyQFO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ensure that Atoms objects has `\"REF_energy\"` and `\"REF_forces\"` attributes after reading the xyz file."
      ],
      "metadata": {
        "id": "DxIzj5DuUkIk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pprint(train[-1].info)\n",
        "pprint(train[-1].arrays)\n",
        "view(train[-1], viewer=\"x3d\")"
      ],
      "metadata": {
        "id": "AfQTkNMfyQv2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Training\n",
        "\n",
        "Now, we're ready to fine-tune the MACE-MP model on your custom dataset."
      ],
      "metadata": {
        "id": "xjAcZGCyyTsr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Running the Training Script\n",
        "\n",
        "We use the mace_run_train command to start the training process."
      ],
      "metadata": {
        "id": "hagRkOHO4oKa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! mace_run_train \\\n",
        "    --name=\"mace_tutorial\" \\\n",
        "    --foundation_model=\"medium\" \\\n",
        "    --train_file=\"train.xyz\" \\\n",
        "    --valid_file=\"valid.xyz\" \\\n",
        "    --test_file=\"test.xyz\" \\\n",
        "    --energy_weight=1.0 \\\n",
        "    --forces_weight=1.0 \\\n",
        "    --energy_key=\"REF_energy\" \\\n",
        "    --forces_key=\"REF_forces\" \\\n",
        "    --E0s=\"foundation\" \\\n",
        "    --lr=1e-3 \\\n",
        "    --weight_decay=1e-8 \\\n",
        "    --batch_size=4 \\\n",
        "    --max_num_epochs=10 \\\n",
        "    --ema \\\n",
        "    --default_dtype=\"float32\" \\\n",
        "    --device=\"cpu\" \\\n",
        "    --seed=0\n"
      ],
      "metadata": {
        "id": "2TcR8JOoyRjq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Key parameters**\n",
        "\n",
        "*   --name: Specifies the name of the training run.\n",
        "*   --foundation_model: Indicates which pre-trained model to start from.\n",
        "*   --train_file, --valid_file, --test_file: Paths to your datasets.\n",
        "*   --energy_weight, --forces_weight: Weights for energy and force terms in the loss function.\n",
        "*   --energy_key, --forces_key: Keys used in the dataset for reference energies and forces.\n",
        "*   --E0s: Specifies how to handle reference energies (using foundation model's zero-point energies).\n",
        "*   --lr: Learning rate.\n",
        "*   --weight_decay: Weight decay for regularization.\n",
        "*   --batch_size: Number of samples per batch.\n",
        "*   --max_num_epochs: Maximum number of training epochs.\n",
        "*   --ema: Use Exponential Moving Average of model parameters.\n",
        "*   --default_dtype: Sets the default data type for computations.\n",
        "*   --device: Specifies the device for computation (cpu or cuda).\n",
        "*   --seed: Seed for random number generators for reproducibility."
      ],
      "metadata": {
        "id": "c5M5qj_l4rrO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check it out other parameters\n",
        "! mace_run_train -h"
      ],
      "metadata": {
        "id": "jkxqTMFdO56d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## [TIPs]\n",
        "\n",
        "\n",
        "1.   **Setting Atomic Numbers**:\n",
        "\n",
        "If you do not explicitly specify `atomic_number`, the model will only support the atomic numbers present in your fine-tuning dataset. For example, if your fine-tuning data contains only copper, the model will not be able to use any other atomic numbers.\n",
        "To prevent this limitation, you can explicitly provide a list of all atomic numbers supported by `mace_mp`.\n",
        "\n",
        "```bash\n",
        "--atomic_number=\"[1, 2, ..., 94]\"\n",
        "```\n",
        "\n",
        "2.   **Setting isolated atom energies**\n",
        "\n",
        "Isolated atom energies are designed for efficient training the mace model as initial atomic energies. You can manually define these values, as shown below:\n",
        "\n",
        "```\n",
        "--E0s={1: 1.304, ... 94: 4.259}\n",
        "```\n",
        "When fine-tuning a foundation model, itâ€™s generally recommended to use \"foundation\" to apply the default settings from the foundation model.\n",
        "Alternatively, you may use \"average\" to compute the average isolated atom energies from your training data; however, this approach is more commonly suited to pretraining.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "v3M3gaCbaVwz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. Evaluation\n",
        "\n",
        "After training, we evaluate the performance of your fine-tuned MACE model."
      ],
      "metadata": {
        "id": "aBhaYVPNyWPm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loading the Fine-Tuned Model\n",
        "\n",
        "We load the fine-tuned model using the mace_mp function."
      ],
      "metadata": {
        "id": "CQCRFxel5OaJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "finetuning_calc = mace_mp(model=\"mace_tutorial.model\", device=\"cpu\")"
      ],
      "metadata": {
        "id": "c-28SNr_yYR6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Calculating Energies and Forces on the Test Set\n",
        "\n",
        "We compute the energies and forces predicted by the fine-tuned model for each configuration in the test set."
      ],
      "metadata": {
        "id": "7RHh80Sf5SAY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "collection = defaultdict(list)\n",
        "for atoms in test:\n",
        "    dist = atoms.info[\"dist\"]\n",
        "\n",
        "    # Calculate the energy and forces from MACE-MP (finetuning)\n",
        "    e_finetuning = finetuning_calc.get_potential_energy(atoms)\n",
        "    f_finetuning = finetuning_calc.get_forces(atoms)\n",
        "\n",
        "    # Collect the data\n",
        "    collection[\"dist\"].append(dist)\n",
        "    collection[\"e_finetuning\"].append(e_finetuning)\n",
        "    collection[\"f_finetuning\"].append(f_finetuning)\n",
        "\n",
        "# merge with df\n",
        "df_total = df.copy()\n",
        "df_finetuning = pd.DataFrame(collection)\n",
        "df_total = pd.merge(df_total, df_finetuning, on=\"dist\")"
      ],
      "metadata": {
        "id": "FkcIGhFlyZeA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Plotting the Comparison\n",
        "\n",
        "We plot the energies from the original MACE-MP, MACE-MP-0b, and the fine-tuned model."
      ],
      "metadata": {
        "id": "1EtS825S5YHr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots(1, 1, figsize=(6, 4))\n",
        "sns.lineplot(data=df_total, x=\"dist\", y=\"e_mace_mp\", label=\"MACE-MP\", marker=\"o\", ax=ax)\n",
        "sns.lineplot(\n",
        "    data=df_total, x=\"dist\", y=\"e_mace_mp_0b\", label=\"MACE-MP-0b\", marker=\"o\", ax=ax\n",
        ")\n",
        "sns.lineplot(\n",
        "    data=df_total,\n",
        "    x=\"dist\",\n",
        "    y=\"e_finetuning\",\n",
        "    label=\"MACE-MP (finetuning)\",\n",
        "    marker=\"o\",\n",
        "    ax=ax,\n",
        ")\n",
        "ax.set_xlabel(\"Distance [Ã…]\")\n",
        "ax.set_ylabel(\"Energy [eV]\")\n",
        "ax.set_ylim(-10, 50)\n",
        "ax.axhline(0, color=\"black\", linestyle=\"--\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Jya4DVQdyalt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The finetuning model now can predict the repusion part well ! ðŸ¤—"
      ],
      "metadata": {
        "id": "9nBZLY7e5bjm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5. Application (MD simulation)\n",
        "\n",
        "Now that we've fine-tuned our MACE model, let's apply it in a molecular dynamics simulation."
      ],
      "metadata": {
        "id": "JVPrBGJwyec8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creating a Bulk Copper Structure\n",
        "\n",
        "We start by creating a bulk face-centered cubic (fcc) copper structure."
      ],
      "metadata": {
        "id": "bCWw8i-X5r2q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "atoms = bulk(\"Cu\", \"fcc\", a=4.6, cubic=True)\n",
        "view(atoms, viewer=\"x3d\")"
      ],
      "metadata": {
        "id": "xMS8-5QiyexR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setting Up the Calculator and MD simulation.\n",
        "\n",
        "We assign our fine-tuned MACE calculator to the atomic structure.\n",
        "Then, Set up very simple Langevin thermostat to control the temperature during the simulation.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "_tMCU9_Q5x1w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set up Calculator\n",
        "atoms.calc = finetuning_calc\n",
        "\n",
        "# Set up initial velocities\n",
        "temperature = 300  # K\n",
        "MaxwellBoltzmannDistribution(atoms, temperature_K=temperature)\n",
        "\n",
        "# Set up the dynamics\n",
        "time_step = 1.0  # fs\n",
        "dyn = Langevin(\n",
        "    atoms,\n",
        "    timestep=time_step * units.fs,\n",
        "    temperature_K=temperature,\n",
        "    friction=0.01 / units.fs,\n",
        "    trajectory=\"Cu_fcc.traj\",\n",
        "    loginterval=10,\n",
        ")\n",
        "\n",
        "# Run the dynamics\n",
        "n_steps = 100\n",
        "dyn.run(\n",
        "    n_steps,\n",
        ")\n",
        "\n",
        "# Read the trajectory\n",
        "traj = read(\"Cu_fcc.traj\", index=\":\")"
      ],
      "metadata": {
        "id": "m2VBWMZ9ygqC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Visualizing the Trajectory\n",
        "\n",
        "After the simulation, we read and visualize the trajectory."
      ],
      "metadata": {
        "id": "yqK4EmZf6CTq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots()\n",
        "\n",
        "def update(frame):\n",
        "    ax.clear()\n",
        "    plot_atoms(traj[frame], ax=ax, show_unit_cell=2)\n",
        "    ax.set_axis_off()\n",
        "    plt.title(f\"Frame {frame}\")\n",
        "    return ax\n",
        "\n",
        "ani = FuncAnimation(fig, func=update, frames=len(traj), repeat=False)\n",
        "display(HTML(ani.to_jshtml()))\n",
        "plt.close(fig)"
      ],
      "metadata": {
        "id": "zlwjiNHSyhwi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# DONE !! ðŸŽ‰"
      ],
      "metadata": {
        "id": "1xP5c6sK6Iwi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Keep in mind that \"finetuning does not always lead to good results\"\n",
        "\n",
        "When finetuning a pretrained model with a limited dataset, the model's weights are updated, often leading to increased overfitting. This process introduces two primary issues during finetuning:\n",
        "\n",
        "## 1. Smoothing (or Softening)\n",
        "\n",
        "Most data points are more likely to be located in equilibrium regions rather than in repulsion regions. For example, MPTraj data represents geometry optimization trajectories, which can lead to a smoothing issue where even the pretrained model (e.g., MACE-MP) ruggles to accurately predict repulsion forces.\n",
        "\n",
        "During finetuning, unlike pre-training which uses a diverse and extensive dataset, the data is limited, resulting in an even more severe smoothing effect.\n",
        "\n",
        "(Check it out the relavalent paper on smoothing. [Overcoming systematic softening in universal machine learning interatomic potentials by finetuning](https://arxiv.org/abs/2405.07105)\n",
        "\n",
        "## 2. Forgetting\n",
        "\n",
        "Forgetting occurs when a finetuned model loses its ability to generalize to data outside the finetuning domain. For instance, if the MPTraj dataset contains information on inorganic materials and we fine-tune the model with organic materials, will the fine-tuned model still maintain its performance on inorganic materials? Unfortunately, the answer is often \"no.\" This degradation is known as the \"forgetting issue.\"\n",
        "\n",
        "To illustrate, consider finetuning `MACE-MP` using a dataset that contains only copper-related data. This finetuning may adversely impact the modelâ€™s performance on predicting the interatomic potential of other elements, such as gold (Au) for this case. The following example explores how fine-tuning with a narrowly focused dataset affects (or disrupt) the foundation model."
      ],
      "metadata": {
        "id": "h7VNghgSbviz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! mace_run_train \\\n",
        "    --name=\"mace_advance_1\" \\\n",
        "    --foundation_model=\"medium\" \\\n",
        "    --train_file=\"train.xyz\" \\\n",
        "    --valid_file=\"valid.xyz\" \\\n",
        "    --test_file=\"test.xyz\" \\\n",
        "    --energy_weight=1.0 \\\n",
        "    --forces_weight=1.0 \\\n",
        "    --energy_key=\"REF_energy\" \\\n",
        "    --forces_key=\"REF_forces\" \\\n",
        "    --atomic_numbers=\"[29, 79]\" \\\n",
        "    --E0s=\"foundation\" \\\n",
        "    --lr=1e-2 \\\n",
        "    --weight_decay=1e-8 \\\n",
        "    --batch_size=4 \\\n",
        "    --max_num_epochs=10 \\\n",
        "    --ema \\\n",
        "    --default_dtype=\"float32\" \\\n",
        "    --device=\"cpu\" \\\n",
        "    --seed=0\n"
      ],
      "metadata": {
        "id": "hvXOGrppb5bS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "distances = np.arange(0.6, 5.1, 0.1)\n",
        "atoms_list = []\n",
        "for dist in distances:\n",
        "    atoms = Atoms(\n",
        "        \"Au2\", positions=[[0, 0, 0], [0, 0, dist]], cell=[20, 20, 20], pbc=True\n",
        "    )\n",
        "    atoms.info[\"dist\"] = dist\n",
        "    atoms_list.append(atoms)"
      ],
      "metadata": {
        "id": "IWaKo97qVPKQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "finetuning_calc = mace_mp(model=\"mace_advance_1.model\", device=\"cpu\")"
      ],
      "metadata": {
        "id": "wZaMVJi6cUgw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "collections = defaultdict(list)\n",
        "for i, atoms in enumerate(atoms_list):\n",
        "    # Calculate the energy and forces from MACE-MP\n",
        "    e_mace_mp = mace_mp_calc.get_potential_energy(atoms)\n",
        "    f_mace_mp = mace_mp_calc.get_forces(atoms)\n",
        "\n",
        "    # Calculate the energy and forces from MACE-MP-0b\n",
        "    e_mace_mp_0b = mace_mp_0b_calc.get_potential_energy(atoms)\n",
        "    f_mace_mp_0b = mace_mp_0b_calc.get_forces(atoms)\n",
        "\n",
        "    # Calculate the energy and forces from MACE-MP (finetuning)\n",
        "    e_finetuning = finetuning_calc.get_potential_energy(atoms)\n",
        "    f_finetuning = finetuning_calc.get_forces(atoms)\n",
        "\n",
        "    # Collect the data\n",
        "    dist = distances[i]\n",
        "    collections[\"dist\"].append(dist)\n",
        "    collections[\"atoms\"].append(atoms)\n",
        "    collections[\"e_mace_mp\"].append(e_mace_mp)\n",
        "    collections[\"f_mace_mp\"].append(f_mace_mp)\n",
        "    collections[\"e_mace_mp_0b\"].append(e_mace_mp_0b)\n",
        "    collections[\"f_mace_mp_0b\"].append(f_mace_mp_0b)\n",
        "    collections[\"e_finetuning\"].append(e_finetuning)\n",
        "    collections[\"f_finetuning\"].append(f_finetuning)\n",
        "df_advance_1 = pd.DataFrame(collections)"
      ],
      "metadata": {
        "id": "_9wXinHgVQs0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots(1, 1, figsize=(6, 4))\n",
        "sns.lineplot(data=df_advance_1, x=\"dist\", y=\"e_mace_mp\", label=\"MACE-MP\", marker=\"o\", ax=ax)\n",
        "sns.lineplot(\n",
        "    data=df_advance_1, x=\"dist\", y=\"e_mace_mp_0b\", label=\"MACE-MP-0b\", marker=\"o\", ax=ax\n",
        ")\n",
        "sns.lineplot(\n",
        "    data=df_advance_1,\n",
        "    x=\"dist\",\n",
        "    y=\"e_finetuning\",\n",
        "    label=\"MACE-MP (finetuning)\",\n",
        "    marker=\"o\",\n",
        "    ax=ax,\n",
        ")\n",
        "ax.set_title(\"Au\")\n",
        "ax.set_xlabel(\"Distance [Ã…]\")\n",
        "ax.set_ylabel(\"Energy [eV]\")\n",
        "ax.set_ylim(-10, 50)\n",
        "ax.axhline(0, color=\"black\", linestyle=\"--\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "09162XV0Wa5N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## How to Mitigate FineTuning Issues\n",
        "\n",
        "To address these issues, consider the following strategies (from my experience..):\n",
        "\n",
        "1. **Lower the Learning Rate**: Reducing the learning rate helps ensure that the changes to the model's weights are subtle, preventing drastic shifts that can lead to overfitting and forgetting.\n",
        "\n",
        "2. **Minimize Weight Update Steps**: Reducing the number of weight update steps helps preserve the pretrained features. High epochs or step counts lead to significant changes in model weights. So finetune the model similar to **\"seasoning lightly\"**.\n",
        "\n",
        "3. **Incorporate Pretraining Data Explicitly**: One way to prevent forgetting is to explicitly add samples from the pre-training dataset during fine-tuning. It appears that MACE repo is developing advanced finetuning techniuqe named `Multihead Replay Fine-Tuning`. You can read more about it in their documentation [here](https://mace-docs.readthedocs.io/en/latest/guide/finetuning.html#multihead-replay-fine-tuning).\n",
        "\n",
        "4. **Utilize Regularization Methods**:  Implementing regularization techniques, such as tuning weight decay, dropout, gradient clipping, can help control overfitting."
      ],
      "metadata": {
        "id": "omV9o1bmzeuL"
      }
    }
  ]
}